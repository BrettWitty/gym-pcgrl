{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pip install tensorflow==1.15\n",
    "#Install stable-baselines as described in the documentation\n",
    "\n",
    "import gym\n",
    "import gym_pcgrl\n",
    "from gym_pcgrl import wrappers\n",
    "\n",
    "from helper import get_exp_name, max_exp_idx, load_model, make_env\n",
    "\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_state(env, step=0, changes=0, total_reward=0, name=\"\"):\n",
    "    fig = plt.figure(10)\n",
    "    plt.clf()\n",
    "    plt.title(\"{} | Step: {} Changes: {} Total Reward: {}\".format(name, step, changes, total_reward))\n",
    "    plt.axis('off')\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "def get_action(env, model, action_type=0):\n",
    "    action = None\n",
    "    if action_type == 0:\n",
    "        action, _ = model.predict(obs)\n",
    "    elif action_type == 1:\n",
    "        action_prob = model.action_probability(obs)[0]\n",
    "        action = np.random.choice(a=list(range(len(action_prob))), size=1, p=action_prob)\n",
    "    else:\n",
    "        action = np.array([env.action_space.sample()])\n",
    "    return action\n",
    "\n",
    "def get_model(game, representation, experiment, **kwargs):\n",
    "    exp_name = get_exp_name(game, representation, experiment, **kwargs)\n",
    "    n = max_exp_idx(exp_name)\n",
    "    if n == 0:\n",
    "        raise Exception('Did not find ranked saved model of experiment: {}'.format(exp_name))\n",
    "    log_dir = 'runs/{}_{}_{}'.format(exp_name, n, 'log')\n",
    "    model = load_model(log_dir)\n",
    "    return model\n",
    "\n",
    "game = \"binary\"\n",
    "representation = \"narrow\"\n",
    "experiment = \"100M\"\n",
    "env_name = '{}-{}-v0'.format(game, representation)\n",
    "inf_kwargs = {\n",
    "    'change_percentage': 0.4\n",
    "}\n",
    "env =  DummyVecEnv([make_env(env_name, representation, 0, None, **inf_kwargs)])\n",
    "kwargs = {\n",
    "    'cropped-size': 28\n",
    "}\n",
    "model = get_model(game, representation, experiment, **kwargs)\n",
    "obs = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "while not done:\n",
    "    action = get_action(env, model, 0)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    total_reward += rewards\n",
    "    if done:\n",
    "        break\n",
    "    show_state(env, infor['iterations'], info['changes'], total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Models for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binary_lambdas = {\n",
    "    'pathlength': lambda info: info['path-length'],\n",
    "    'regions': lambda info: info['regions'],\n",
    "    'iterations': lambda info: info['iterations'] / (1.0 * info['max_iterations']),\n",
    "    'changes': lambda info: info['changes'] / (1.0 * info['max_changes']),\n",
    "    'pathlength_const': lambda info: [0, 1][info['path-length'] >= 48],\n",
    "    'regions_const': lambda info: [0, 1][info['regions'] == 1],\n",
    "}\n",
    "zelda_lambdas = {\n",
    "    'player': lambda info: info['player'],\n",
    "    'key': lambda info: info['key'],\n",
    "    'door': lambda info: info['door'],\n",
    "    'regions': lambda info: info['regions'],\n",
    "    'nearestenemy': lambda info: info['nearest-enemy'],\n",
    "    'pathlength': lambda info: info['path-length'],\n",
    "    'iterations': lambda info: info['iterations'] / (1.0 * info['max_iterations']),\n",
    "    'changes': lambda info: info['changes'] / (1.0 * info['max_changes']),\n",
    "    'player_const': lambda info: [0, 1][info['player'] == 1],\n",
    "    'key_const': lambda info: [0, 1][info['key'] == 1],\n",
    "    'door_const': lambda info: [0, 1][info['door'] == 1],\n",
    "    'regions_const': lambda info: [0, 1][info['regions'] == 1],\n",
    "    'nearestenemy_const': lambda info: [0, 1][info['nearest-enemy'] >= 4],\n",
    "    'pathlength_const': lambda info: [0, 1][info['path-length'] >= 16],\n",
    "}\n",
    "sokoban_lambdas = {\n",
    "    'player': lambda info: info['player'],\n",
    "    'crate': lambda info: info['crate'],\n",
    "    'target': lambda info: info['target'],\n",
    "    'regions': lambda info: info['regions'],\n",
    "    'sollength': lambda info: info['sol-length'],\n",
    "    'iterations': lambda info: info['iterations'] / (1.0 * info['max_iterations']),\n",
    "    'changes': lambda info: info['changes'] / (1.0 * info['max_changes']),\n",
    "    'player_const': lambda info: [0, 1][info['player'] == 1],\n",
    "    'ratio_const': lambda info: [0, 1][info['crate'] == info['target'] and info['crate'] > 0],\n",
    "    'sollength_const': lambda info: [0, 1][info['sol-length'] >= 18],\n",
    "}\n",
    "lambdas = {\n",
    "    'binary': binary_lambdas,\n",
    "    'zelda': zelda_lambdas,\n",
    "    'sokoban': sokoban_lambdas\n",
    "}\n",
    "\n",
    "def get_hamming_diversity(lvls):\n",
    "    hamming = []\n",
    "    for i in range(len(lvls)):\n",
    "        lvl1 = lvls[i]\n",
    "        lvl_hamming = []\n",
    "        for j in range(len(lvls)):\n",
    "            lvl2 = lvls[j]\n",
    "            if i != j:\n",
    "                diff = np.clip(abs(lvl1 - lvl2), 0, 1)\n",
    "                lvl_hamming.append(diff.sum())\n",
    "        hamming.append(np.mean(lvl_hamming) / (lvls[0].shape[0] * lvls[0].shape[1]))\n",
    "    return hamming\n",
    "\n",
    "def sample_data(sample_size, env, lambdas):\n",
    "    sample_info = {}\n",
    "    lvls = []\n",
    "    for name in lambdas:\n",
    "        sample_info[name] = []\n",
    "    for i in range(sample_size):\n",
    "        done = False\n",
    "        obs = env.reset()\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, rewards, done, info = env.step(action)\n",
    "        lvls.append(env.get_attr('pcgrl_env')[0]._rep.get_observation()['map'])\n",
    "        for name in lambdas:\n",
    "            sample_info[name].append(lambdas[name](info[0]))\n",
    "    sample_info['diversity'] = get_hamming_diversity(lvls)\n",
    "    return sample_info\n",
    "\n",
    "def get_model(game, representation, experiment, **kwargs):\n",
    "    exp_name = get_exp_name(game, representation, experiment, **kwargs)\n",
    "    n = max_exp_idx(exp_name)\n",
    "    if n == 0:\n",
    "        raise Exception('Did not find ranked saved model of experiment: {}'.format(exp_name))\n",
    "    log_dir = 'runs/{}_{}_{}'.format(exp_name, n, 'log')\n",
    "    model = load_model(log_dir)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Collect Models' Results for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_name = \"binary\"\n",
    "sample_size = 100\n",
    "rep_names = [\"narrow\", \"turtle\", \"wide\"]\n",
    "exp_names = [\"noaction_heatmap_changes_100M.zip\", \"heatmap_changes_100M.zip\", \"100M.pkl\"]\n",
    "kwargs={\n",
    "    'cropped_size': 28\n",
    "}\n",
    "\n",
    "result = {}\n",
    "for i in range(len(exp_names)):\n",
    "    r_name = rep_names[i]\n",
    "    e_name = exp_names[i]\n",
    "    m_name = get_exp_name(game, representation, experiment)\n",
    "    env_name = \"{}-{}-v0\".format(p_name, r_name)\n",
    "    model = get_model(p_name, r_name, e_name)\n",
    "    result[m_name] = {}\n",
    "    for ch_perc in np.arange(0, 1.01, 0.1):\n",
    "        print(\"Testing {} at change percentage of {}\".format(m_name, ch_perc))\n",
    "        kwargs['change_percentage'] = ch_perc\n",
    "        env = DummyVecEnv([make_env(env_name, r_name, 0, None, **kwargs)])\n",
    "        temp_result = sample_data(sample_size, env, lambdas[p_name])\n",
    "        for name in temp_result:\n",
    "            if not(name in result[m_name]):\n",
    "                result[m_name][name] = []\n",
    "            result[m_name][name].append(np.mean(temp_result[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render Models' Results Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(results, name):\n",
    "    output = {}\n",
    "    for n in results:\n",
    "        output[n] = results[n][name]\n",
    "    return output\n",
    "\n",
    "def plt_dict(p_dict, y_title, file_name):\n",
    "    plt.figure()\n",
    "    names = []\n",
    "    for name in p_dict:\n",
    "        plt.plot(np.array(np.arange(0.0,1.01,0.1)),p_dict[name])\n",
    "        names.append(name)\n",
    "    plt.legend(names)\n",
    "    plt.xlim(0.0,1.0)\n",
    "    plt.xticks(np.array(np.arange(0.0,1.01,0.1)), rotation=90)\n",
    "    plt.xlabel('change percentage')\n",
    "    plt.ylabel(y_title)\n",
    "    plt.savefig(file_name + \".pdf\")\n",
    "\n",
    "for n in lambdas[p_name]:\n",
    "    plt_dict(get_data(result, n), n, n)\n",
    "plt_dict(get_data(result, 'diversity'), 'diversity', 'diversity')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
